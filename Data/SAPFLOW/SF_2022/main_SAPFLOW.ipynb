{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "483341b3",
   "metadata": {},
   "source": [
    "# Empirical corrections and Data cleaning for SFM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e7a776",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "partial-fellowship",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e0e2eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "path_cwd=Path.cwd()\n",
    "path_input=str(path_cwd)+'/Data_input/'\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(path_cwd)+'/Functions')\n",
    "import baseline\n",
    "import reading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5885c520",
   "metadata": {},
   "source": [
    "### Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dacfaca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is parsing the inputfiles.csv file and creating a list of tuples with the following structure: [(name,tree,date,{Dict})]\n",
    "from csv import DictReader, reader\n",
    "\n",
    "with open(path_input+'inputfiles_2022.csv', encoding='utf-8-sig') as read_obj:\n",
    "    dict_reader = DictReader(read_obj)\n",
    "    list_of_dict = list(dict_reader)\n",
    " \n",
    "    name_=[[list_of_dict[i].pop(key) for i in range(len(list_of_dict))]for key in [\"Filename\",\"Tree\",\"Start_date\",\"Soil\"]] #extract string columns: Filename,Tree, Date (if applicable) .pop(key):removes specified element from list or dict \n",
    "\n",
    "    res = [dict([key, float(value)] for key, value in dicts.items()) for dicts in list_of_dict]#this will make all values integers ONLY WORKS if all values in file are numerical\n",
    "    \n",
    "    inputfiles=[(name_[0][i],name_[1][i],name_[2][i],name_[3][i],res[i]) for i in range(len(list_of_dict))] #list of tuples: [(name,tree,date,{Dict})]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a10c27",
   "metadata": {},
   "source": [
    "### Main \n",
    "- Reading, cleaning and defining values for correction \n",
    "- Applying corrections from manual \n",
    "- Correction of baseline through linear regression\n",
    "- Saving output files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb50e238",
   "metadata": {},
   "outputs": [],
   "source": [
    "#General variables\n",
    "\n",
    "#READING\n",
    "SF_cols=['Date','Time','UO','UI','CO','CI','SFO','SFI','MaxTdO','MaxTuO','RiseTdO',\n",
    "         'RiseTuO','RatioOut','MaxTdI','MaxTuI','RiseTdI','RiseTuI','RatioIn',\n",
    "         'Pulse','BatteryVolt','BatteryT','ExternalPowerPresent','ExternalPowerVoltage',\n",
    "         'ExternalPowerCurrent','Message']\n",
    "\n",
    "#THERMAL DIFFUSIVITY\n",
    "RHO=997 #water density (kg/m3)\n",
    "CW=1200 #specific heat capacity of wood matrix (J kg-1 C-1)\n",
    "CS=4182 #specific heat capacity of sap ( J kg-1 C-1 )\n",
    "KS=0.5984 #thermal conductivity of water (J m-1 s-1 Â°C-1)\n",
    "\n",
    "#CROSS SECTIONAL AREA\n",
    "import math\n",
    "\n",
    "pi=math.pi #define pi to use it \n",
    "BDI= 0 #bark depth at installation, if some needle is sticking out I can change value (cm) \n",
    "\n",
    "# WOUNDING COEFFICIENT\n",
    "#here we assume a wound of 2 mm check manual if user want to change values\n",
    "B=1.9216\n",
    "b=1.8558\n",
    "c=-0.0018\n",
    "d=0.0003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7add0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from distutils.version import LooseVersion\n",
    "from packaging import version\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b428f541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SF_W_SFM1J20P-DF49GT-2022-incomplete.csv\n",
      "SF_W_SFM1I60R-ES48GT-2022-incomplete.csv\n",
      "SF_W_SFM1I60Q-DF21LS-2022-incomplete.csv\n",
      "SF_W_SFM1K308-ES50LS-2022-incomplete.csv\n",
      "SF_W_SFM1I60T-DF03US-2022-incomplete.csv\n",
      "SF_W_SFM1J406-ES01US-2022-incomplete.csv\n",
      "SF_W_SFM1J20O-DF27US-2022-incomplete.csv\n",
      "SF_W_SFM1J20N-ES42US-2022-incomplete.csv\n"
     ]
    }
   ],
   "source": [
    "name_sensor=[]\n",
    "sf_out_total=[]\n",
    "\n",
    "for i,(name,tree,ini_date,soil,options) in enumerate(inputfiles):\n",
    "        from reading import read_sf1 \n",
    "        SF=read_sf1(path_input,SF_cols,name)      \n",
    "\n",
    "        ########THERMAL DIFFUSIVITY \n",
    "        BD,SD,DOB=options['Bark_depth'],options['SW_depth'],options['Diameter'] #bark depth (cm), SW depth (cm), diameter outer bark (cm)\n",
    "        FW,DW,V=options['FW'],options['DW'],options['Vol'] #fresh weight (kg), #dry weight (kg), #volume (cm3)\n",
    "        WC=FW-DW #WATER CONTENT (kg)\n",
    "        MC=WC/DW #MOISTURE CONTENT (%)\n",
    "        WD=(DW)/(V/1000000) #WOOD DENSITY (kg/m3)\n",
    "        C= ((DW*CW)+CS*(FW-DW))/FW #SPECIFIC HEAT CAPACITY OF GREEN WOOD (J kg-1 C-1)\n",
    "        FV= 1-(((WD*0.6536)+MC)/1000) #VOID FRACTION (no dimensions)\n",
    "        a1=20*FV\n",
    "        a2=21-a1\n",
    "        KW=0.04182*a2 #THERMAL CONDUCTIVITY OF DRY WOOD (J m-1 s-1 C-1)\n",
    "        a3=WD/RHO\n",
    "        a4=MC*a3\n",
    "        KGW=(KS*a4)+(KW*(1-a4)) #THERMAL CONDUCTIVITY green/fresh wood (J m-1 s-1 C-1)\n",
    "        k=(KGW/(C*WD))*10000 #****THERMAL DIFFUSIVITY cm2/s****   \n",
    "\n",
    "        ########SOIL AND ENVIRONMENTAL\n",
    "        from reading import sf_env\n",
    "        SF_W=sf_env(path_input,ini_date,SF,k)\n",
    "        SF_W['HPVI_o'],SF_W['HPVO_o']=SF_W['HPVI'],SF_W['HPVO']\n",
    "\n",
    "\n",
    "        #########48 correction\n",
    "        if options['Output'] == 2:\n",
    "                SF_1= SF_W.copy()\n",
    "                hpvo=SF_1['HPVO'].loc['2022-05-25  22:30:00':'2022-06-29 14:00:00']*-1 \n",
    "                hpvi=SF_1['HPVO'].loc['2022-05-25  22:30:00':'2022-06-29 14:00:00']*-1     \n",
    "                SF_W['HPVO'].loc['2022-05-25  22:30:00':'2022-06-29 14:00:00']=hpvo\n",
    "                SF_W['HPVI'].loc['2022-05-25  22:30:00':'2022-06-29 14:00:00']=hpvi \n",
    "\n",
    "        ########BASELINE CORRECTION \n",
    "        from baseline import baseline_LR_DLR \n",
    "        hpvi_lr,hpvi_dlr,TVC=baseline_LR_DLR(SF_W,nam='HPVI')\n",
    "        hpvo_lr,hpvo_dlr,TVC=baseline_LR_DLR(SF_W,nam='HPVO')\n",
    "        SF_corr=SF_W.drop(columns=['UO', 'UI', 'MaxTdO', 'MaxTuO', 'RiseTdO', 'RiseTuO', 'RatioOut','MaxTdI', 'MaxTuI', 'RiseTdI', 'RiseTuI', 'RatioIn'])\n",
    "        SF_corr['HPVI_LR'],SF_corr['HPVI'],SF_corr['HPVO_LR'],SF_corr['HPVO'],SF_corr['TVC']=hpvi_lr,hpvi_dlr,hpvo_lr,hpvo_dlr,TVC #FOR THE REST OF THE ANALYSIS THE HPV DLR VALUES ARE USED\n",
    "\n",
    "        ########WOUNDING COEFFICIENT CORRECTIONS \n",
    "        #DLR\n",
    "        UO=SF_corr['HPVO'] #uncorrected heat pulse velocity for outer sensor (cm/h)\n",
    "        UI=SF_corr['HPVI'] #uncorrected hpv for inner sensor (cm/h)\n",
    "        VCO=b*UO+c*(UO.pow(2))+d*(UO.pow(3)) #eq 6 pp 25 in mmanual ()\n",
    "        VCI=b*UI+c*(UI.pow(2))+d*(UI.pow(3))\n",
    "        #LR\n",
    "        UOLR=SF_corr['HPVO_LR'] #uncorrected heat pulse velocity for outer sensor (cm/h)\n",
    "        UILR=SF_corr['HPVI_LR'] #uncorrected hpv for inner sensor (cm/h)\n",
    "        VCOLR=b*UOLR+c*(UOLR.pow(2))+d*(UOLR.pow(3)) #eq 6 pp 25 in mmanual ()\n",
    "        VCILR=b*UILR+c*(UILR.pow(2))+d*(UILR.pow(3))\n",
    "        #orig\n",
    "        UO_o=SF_corr['HPVO_o'] #uncorrected heat pulse velocity for outer sensor (cm/h)\n",
    "        UI_o=SF_corr['HPVI_o'] #uncorrected hpv for inner sensor (cm/h)\n",
    "        VCO_o=b*UO_o+c*(UO_o.pow(2))+d*(UO_o.pow(3)) #eq 6 pp 25 in mmanual ()\n",
    "        VCI_o=b*UI_o+c*(UI_o.pow(2))+d*(UI_o.pow(3))\n",
    "\n",
    "\n",
    "        ########SAP VELOCITY\n",
    "        #DLR\n",
    "        SF_corr['Sap velocity corr OUT (cm/h)']=(VCO*WD*(CW+MC*CS))/(RHO*CS)\n",
    "        SF_corr['Sap velocity corr IN (cm/h)']=(VCI*WD*(CW+MC*CS))/(RHO*CS)\n",
    "        #LR\n",
    "        SF_corr['Sap velocity corr OUT_LR (cm/h)']=(VCOLR*WD*(CW+MC*CS))/(RHO*CS)\n",
    "        SF_corr['Sap velocity corr IN_LR (cm/h)']=(VCILR*WD*(CW+MC*CS))/(RHO*CS)\n",
    "        #orginal\n",
    "        SF_corr['Sap velocity corr OUT_o (cm/h)']=(VCO_o*WD*(CW+MC*CS))/(RHO*CS)\n",
    "        SF_corr['Sap velocity corr IN_o (cm/h)']=(VCI_o*WD*(CW+MC*CS))/(RHO*CS)\n",
    "\n",
    "\n",
    "        ########CROSS SECTIONAL AREA\n",
    "        BD,SD,DOB=options['Bark_depth'],options['SW_depth'],options['Diameter'] #bark depth (cm), SW depth (cm), diameter outer bark (cm)\n",
    "        R=DOB/2 # tree radius (cm)\n",
    "        XR=R-BD # xylem radius (sapwood+heartwood) (cm)\n",
    "        HR=XR-SD # heartwood radius (cm)\n",
    "        OSD=1.25-BDI # outer sensor depth (cm)\n",
    "        ISD= 2.75-BDI # inner sensor depth (cm)\n",
    "        MPD=(ISD-OSD)/2 #mid distance between 2 sensors (cm) =0.75\n",
    "\n",
    "        AWo=OSD+MPD #outer annulus width (cm)\n",
    "        AWi=ISD+MPD-AWo #inner annulus width (cm)\n",
    "        MPR=XR-AWo # mid point radius \n",
    "        TSA=pi*((XR**2)-(HR**2)) #Total sap wood area (cm2)\n",
    "        #print (TSA,tree)\n",
    "        \n",
    "        #A1:outer annulus area (cm2)\n",
    "        #A2:inner annulus area (cm2)\n",
    "        #A3:remainder annulus area (cm2)\n",
    "        if (AWo>SD) & ((ISD+MPD)>SD): #just outer sensor, small SD\n",
    "                A1=TSA\n",
    "                A2=0\n",
    "                A3=0\n",
    "                SF_corr['Sap velocity (cm/h)']=SF_corr['Sap velocity corr OUT (cm/h)']\n",
    "                SF_corr['Sap velocity_LR (cm/h)']=SF_corr['Sap velocity corr OUT_LR (cm/h)']\n",
    "                SF_corr['Sap velocity_o (cm/h)']=SF_corr['Sap velocity corr OUT_o (cm/h)']\n",
    "                \n",
    "        elif (AWo<SD) & ((ISD+MPD)<SD): #in out and remainder area\n",
    "                A1=pi*((XR**2)-(MPR**2))\n",
    "                A2=pi*((MPR**2)-((MPR-AWi)**2))\n",
    "                A3=pi*(((MPR-AWi)**2)-(HR**2))\n",
    "                SF_corr['Sap velocity (cm/h)']=(SF_corr['Sap velocity corr IN (cm/h)']+SF_corr['Sap velocity corr OUT (cm/h)'])/2\n",
    "                SF_corr['Sap velocity_LR (cm/h)']=(SF_corr['Sap velocity corr IN_LR (cm/h)']+SF_corr['Sap velocity corr OUT_LR (cm/h)'])/2      \n",
    "                SF_corr['Sap velocity_o (cm/h)']=(SF_corr['Sap velocity corr IN_o (cm/h)']+SF_corr['Sap velocity corr OUT_o (cm/h)'])/2   \n",
    "\n",
    "        else: # just outer but some extra area\n",
    "                A1=pi*((XR**2)-(MPR**2))\n",
    "                A2=0\n",
    "                A3=pi*((MPR**2)-((HR)**2))\n",
    "                SF_corr['Sap velocity (cm/h)']=SF_corr['Sap velocity corr OUT (cm/h)']\n",
    "                SF_corr['Sap velocity_LR (cm/h)']=SF_corr['Sap velocity corr OUT_LR (cm/h)']\n",
    "                SF_corr['Sap velocity_o (cm/h)']=SF_corr['Sap velocity corr OUT_o (cm/h)']\n",
    "\n",
    "\n",
    "        ########SAPFLOW \n",
    "        #DLR\n",
    "        SF_corr['Sap flow corr OUT (cm3/h)']=SF_corr['Sap velocity corr OUT (cm/h)']*A1 # (cm3/h)\n",
    "        SF_corr['Sap flow corr IN (cm3/h)']=SF_corr['Sap velocity corr IN (cm/h)']*A2 #if we take density of water 0.001kg/cm3 we can multiply this value by 1/1000\n",
    "        n=2 #n=1 if we assume remainder has same velocity as inner otherwise we assume linear decay (n=2)\n",
    "        SF_corr['Sap flow corr REM (cm3/h)']=((SF_corr['Sap velocity corr IN (cm/h)']/n)*A3)\n",
    "        SF_corr['Total SF (cm3/h)']=SF_corr['Sap flow corr OUT (cm3/h)']+SF_corr['Sap flow corr IN (cm3/h)']+SF_corr['Sap flow corr REM (cm3/h)']\n",
    "        #LR\n",
    "        SF_corr['Sap flow corr OUT_LR (cm3/h)']=SF_corr['Sap velocity corr OUT_LR (cm/h)']*A1 # (cm3/h)\n",
    "        SF_corr['Sap flow corr IN_LR (cm3/h)']=SF_corr['Sap velocity corr IN_LR (cm/h)']*A2 #if we take density of water 0.001kg/cm3 we can multiply this value by 1/1000\n",
    "        n=2 #n=1 if we assume remainder has same velocity as inner otherwise we assume linear decay (n=2)\n",
    "        SF_corr['Sap flow corr REM_LR (cm3/h)']=((SF_corr['Sap velocity corr IN_LR (cm/h)']/n)*A3)\n",
    "        SF_corr['Total SF_LR (cm3/h)']=SF_corr['Sap flow corr OUT_LR (cm3/h)']+SF_corr['Sap flow corr IN_LR (cm3/h)']+SF_corr['Sap flow corr REM_LR (cm3/h)']\n",
    "        #original \n",
    "        SF_corr['Sap flow corr OUT_o (cm3/h)']=SF_corr['Sap velocity corr OUT_o (cm/h)']*A1 # (cm3/h)\n",
    "        SF_corr['Sap flow corr IN_o (cm3/h)']=SF_corr['Sap velocity corr IN_o (cm/h)']*A2 #if we take density of water 0.001kg/cm3 we can multiply this value by 1/1000\n",
    "        n=2 #n=1 if we assume remainder has same velocity as inner otherwise we assume linear decay (n=2)\n",
    "        SF_corr['Sap flow corr REM_o (cm3/h)']=((SF_corr['Sap velocity corr IN_o (cm/h)']/n)*A3)\n",
    "        SF_corr['Total SF_o (cm3/h)']=SF_corr['Sap flow corr OUT_o (cm3/h)']+SF_corr['Sap flow corr IN_o (cm3/h)']+SF_corr['Sap flow corr REM_o (cm3/h)']\n",
    "\n",
    "\n",
    "\n",
    "        #######INTERPOLATION\n",
    "        SF_corr['Total SF (cm3/h)']=SF_corr['Total SF (cm3/h)'].interpolate(option='polynomial',limit=10) # \n",
    "        SF_corr['Total SF_LR (cm3/h)']=SF_corr['Total SF_LR (cm3/h)'].interpolate(option='polynomial',limit=10)\n",
    "        SF_corr['Total SF_o (cm3/h)']=SF_corr['Total SF_o (cm3/h)'].interpolate(option='polynomial',limit=10)\n",
    "\n",
    "        SF_corr['Sap velocity (cm/h)']=SF_corr['Sap velocity (cm/h)'].interpolate(option='polynomial',limit=10)\n",
    "        SF_corr['Sap velocity_LR (cm/h)']=SF_corr['Sap velocity_LR (cm/h)'].interpolate(option='polynomial',limit=10)\n",
    "        SF_corr['Sap velocity_o (cm/h)']=SF_corr['Sap velocity_o (cm/h)'].interpolate(option='polynomial',limit=10)\n",
    "\n",
    "        #########APPEND\n",
    "        sf_out_w=SF_corr.copy().drop(columns=['HPVI', 'HPVO', 'HPVI_LR', 'HPVO_LR','HPVI_o', 'HPVO_o', 'TVC', 'Sap velocity corr OUT (cm/h)','Sap velocity corr IN (cm/h)','Sap velocity corr OUT_LR (cm/h)','Sap velocity corr IN_LR (cm/h)','Sap velocity corr OUT_o (cm/h)','Sap velocity corr IN_o (cm/h)','Sap flow corr OUT (cm3/h)','Sap flow corr IN (cm3/h)','Sap flow corr REM (cm3/h)','Sap flow corr OUT_LR (cm3/h)','Sap flow corr IN_LR (cm3/h)','Sap flow corr REM_LR (cm3/h)','Sap flow corr OUT_o (cm3/h)','Sap flow corr IN_o (cm3/h)','Sap flow corr REM_o (cm3/h)','Sap velocity_LR (cm/h)','Sap velocity_o (cm/h)','Total SF_LR (cm3/h)','Total SF_o (cm3/h)'])\n",
    "        nam=os.path.splitext(name)[0]+ \"-\" + tree\n",
    "        name_sensor.append(nam)\n",
    "        sf_out_total.append(sf_out_w)\n",
    "\n",
    "        #########OUTPUT FILES \n",
    "        path_cwd = str(Path.cwd())\n",
    "        path_corrsf = path_cwd + \"/Data_output/Incomplete_data/\"\n",
    "        path_TS= str(Path.cwd().parents[2]) #moves two directories up\n",
    "        path_analysis= path_TS + \"/ANALYSIS/Input_files/\" \n",
    "\n",
    "        for dir in [path_corrsf,path_analysis]:\n",
    "                sf_out_w.to_csv(dir + \"SF_W_\"+ nam + \"-2022-incomplete\" + \".csv\", index = True)\n",
    "\n",
    "        print(\"SF_W_\"+ nam + \"-2022-incomplete\" + \".csv\")\n",
    "\n",
    "        #########PLOTTING\n",
    "        # import warnings\n",
    "        # warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "        # print(tree)\n",
    "        # fig = px.line()\n",
    "        # fig.add_scatter(x=SF_corr.index.to_series(), y=SF_corr['Total SF (cm3/h)'] ,name='Total sap (cm3/h)')\n",
    "        # fig.add_scatter(x=SF_corr.index.to_series(), y=SF_corr['Total SF_LR (cm3/h)'] ,name='Total sap_LR (cm3/h)')\n",
    "        # fig.add_scatter(x=SF_corr.index.to_series(), y=SF_corr['Total SF_o (cm3/h)'] ,name='Total sap_original (cm3/h)')\n",
    "        # fig.show()\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ae86a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dates = set(sf_out_total[0].index)\n",
    "#print(common_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ae2075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_sections = []\n",
    "for df in sf_out_total:\n",
    "    complete_mask = ~df['Total SF (cm3/h)'].isnull() & ~df['Sap velocity (cm/h)'].isnull()\n",
    "    complete_sections.append(complete_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cac5a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_regressions = []\n",
    "for i, df in enumerate(sf_out_total):\n",
    "    complete_mask = complete_sections[i]\n",
    "    #x = df.values[complete_mask]\n",
    "    best_r_squared = 0\n",
    "    best_regression = None\n",
    "\n",
    "    for j, other_df in enumerate(sf_out_total):\n",
    "            if i != j:\n",
    "                other_complete_mask = complete_sections[j]\n",
    "                #other_x = other_df.values[other_complete_mask]\n",
    "\n",
    "\n",
    "                #print (len(x), len(other_x))\n",
    "                #x, y = x[complete_mask], x[complete_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "877f567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for name,df in zip(name_sensor,sf_out_total): \n",
    "    incomplete_df=[]\n",
    "    incomplete_mask = df['Total SF (cm3/h)'].isnull()\n",
    "    df['Total SF (cm3/h)'][~incomplete_mask]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rw_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
